# -*- coding: utf-8 -*-
"""KNN_XOR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_aonh2sLH9N4XNXQ4su5HGFQ2rwi47FQ
"""

import numpy as np
import matplotlib.pyplot as plt
from math import sqrt

# calculate the Euclidean distance between two vectors
def euclidean_distance(row1, row2):
	distance = 0.0
	for i in range(len(row1)-1):
		distance += (row1[i] - row2[i])**2
	return sqrt(distance)

# Locate the most similar neighbors
def get_neighbors(train, test_row, num_neighbors):
	distances = list()
	for train_row in train:
		dist = euclidean_distance(test_row, train_row)
		distances.append((train_row, dist))
	distances.sort(key=lambda tup: tup[1])
	neighbors = list()
	for i in range(num_neighbors):
		neighbors.append(distances[i][0])
	return neighbors

# Make a classification prediction with neighbors
def predict_classification(train, test_row, num_neighbors):
	neighbors = get_neighbors(train, test_row, num_neighbors)
 
 # checking each neighbor for there classification
	output_values = [row[-1] for row in neighbors]

  # determines which classification is the greatest 
	prediction = max(set(output_values), key=output_values.count)
	return prediction

x1 =np.concatenate([np.random.uniform(0, 100, 100), np.random.uniform(-100, 0, 100)]) #red
y1 =np.concatenate([np.random.uniform(-100, 0, 100), np.random.uniform(0, 100, 100)])

x2 =np.concatenate([np.random.uniform(0, 100, 100), np.random.uniform(-100, 0, 100)])
y2 =np.concatenate([np.random.uniform(0, 100, 100), np.random.uniform(-100, 0, 100)])

# 1 being false and 0 being true, as it is in C
set_1 = [[x, y, 0] for x in x1 for y in y1]
set_2 = [[x, y, 1] for x in x2 for y in y2]
final_data = set_1 + set_2

# prediction = predict_classification(dataset, dataset[0], 3)
# print('Expected %d, Got %d.' % (dataset[0][-1], prediction))